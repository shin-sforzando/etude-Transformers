# etude-Transformers

[![Bump Version](https://github.com/shin-sforzando/etude-Transformers/workflows/Bump%20Version/badge.svg)](https://github.com/shin-sforzando/etude-Transformers/actions?query=workflow:%22Bump+Version%22)
[![Commitizen friendly](https://img.shields.io/badge/commitizen-friendly-brightgreen.svg)](http://commitizen.github.io/cz-cli/)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)

|![Screenshot 1](https://placehold.jp/32/3d4070/ffffff/720x480.png?text=Screenshot%201)|![Screenshot 2](https://placehold.jp/32/703d40/ffffff/720x480.png?text=Screenshot%202)|
|:---:|:---:|
|Screenshot 1|Screenshot 2|

> Transformers provides general-purpose architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNetâ€¦) for Natural Language Understanding (NLU) and Natural Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between TensorFlow 2.0 and PyTorch.

- [Requirements](#requirements)
- [How to](#how-to)
  - [Setup](#setup)
  - [Develop](#develop)
  - [Run](#run)
  - [Lint](#lint)
  - [Test](#test)
  - [Deploy](#deploy)
  - [Document](#document)
    - [CHANGELOG.md](#changelogmd)
- [Misc](#misc)
- [Notes](#notes)
  - [LICENSE](#license)
  - [Contributors](#contributors)

## Requirements

- A (Version x.y.z or higher)
  - B
  - C
- D
  - E

## How to

### Setup

```shell
(T.B.D.)
```

### Develop

```shell
(T.B.D.)
```

### Run

```shell
(T.B.D.)
```

### Lint

```shell
(T.B.D.)
```

### Test

```shell
(T.B.D.)
```

### Deploy

```shell
(T.B.D.)
```

### Document

```shell
(T.B.D.)
```

#### CHANGELOG.md

```shell
cz changelog
```

## Misc

## Notes

This repository is [Commitizen](https://commitizen.github.io/cz-cli/) friendly.

### LICENSE

See [LICENSE](LICENSE).

### Contributors

- [Shin'ichiro Suzuki](https://github.com/shin-sforzando)
